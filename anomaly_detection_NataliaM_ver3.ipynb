{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natmartem/natmartem.github.io/blob/main/anomaly_detection_blank_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context\n",
        "**In this notebook, you will implement various anomaly detection techniques** using a pretrained ResNet model and datasets like the [CIFAR-10](https://paperswithcode.com/dataset/cifar-10), [CIFAR-100](https://paperswithcode.com/dataset/cifar-100), and [Street View House Numbers](https://paperswithcode.com/dataset/svhn).\n",
        "\n",
        "## Note:\n",
        "The code will run much faster with a GPU. To enable this, click on **Runtime > Change runtime type > Hardware Accelerator > select GPU**.\n",
        "\n",
        "It could be that a GPU is not is available. In this case, select \"None\" as a hardware accelerator. The code will still work.\n",
        "\n",
        "## Contributers:\n",
        "Jason Ding\n",
        "\n",
        "\n",
        "\n",
        "--------"
      ],
      "metadata": {
        "id": "rVDP9Kt-EoJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloads\n",
        "\n",
        "The following cells **install libaries and download a pretrained model**.\n",
        "\n",
        "(Note: the downloads may take up to a minute to finish. You may get errors about dependency conflicts with `torchtext`, `torchdata`, and `torchaudio`. These libraries are not necessary so you can safely ignore these errors)."
      ],
      "metadata": {
        "id": "xTF95S98RyLT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qo_2N4BQ3vdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6016462-6919-43e8-8c20-338ba713849d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-06 11:15:15--  https://github.com/hendrycks/outlier-exposure/raw/master/CIFAR/snapshots/baseline/cifar10_wrn_baseline_epoch_99.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hendrycks/outlier-exposure/master/CIFAR/snapshots/baseline/cifar10_wrn_baseline_epoch_99.pt [following]\n",
            "--2023-08-06 11:15:15--  https://raw.githubusercontent.com/hendrycks/outlier-exposure/master/CIFAR/snapshots/baseline/cifar10_wrn_baseline_epoch_99.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9037421 (8.6M) [application/octet-stream]\n",
            "Saving to: ‘cifar10_wrn_baseline_epoch_99.pt’\n",
            "\n",
            "cifar10_wrn_baselin 100%[===================>]   8.62M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-06 11:15:16 (80.0 MB/s) - ‘cifar10_wrn_baseline_epoch_99.pt’ saved [9037421/9037421]\n",
            "\n",
            "--2023-08-06 11:15:16--  https://raw.githubusercontent.com/hendrycks/pre-training/master/robustness/adversarial/models/wrn_with_pen.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3913 (3.8K) [text/plain]\n",
            "Saving to: ‘wrn_with_pen.py’\n",
            "\n",
            "wrn_with_pen.py     100%[===================>]   3.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-06 11:15:16 (68.6 MB/s) - ‘wrn_with_pen.py’ saved [3913/3913]\n",
            "\n",
            "Collecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (4.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.27.1)\n",
            "Collecting torch==1.11.0 (from torchvision==0.12.0)\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.4)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0 torchvision-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/hendrycks/outlier-exposure/raw/master/CIFAR/snapshots/baseline/cifar10_wrn_baseline_epoch_99.pt\n",
        "!wget https://raw.githubusercontent.com/hendrycks/pre-training/master/robustness/adversarial/models/wrn_with_pen.py\n",
        "!pip3 install torchvision==0.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pRRReMOZyRLW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.metrics as sk                    # https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "import torch.nn.functional as F                 # https://pytorch.org/docs/stable/nn.functional.html\n",
        "from torchvision import datasets                # https://pytorch.org/vision/stable/datasets.html\n",
        "\n",
        "from wrn_with_pen import WideResNet\n",
        "from torch.utils.data import Dataset            # https://pytorch.org/docs/stable/data.html\n",
        "import torchvision.transforms as transforms     # https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "prefetch = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model and Datasets\n",
        "\n",
        "The **following cells load the ResNet model, CIFAR-10 dataset, and out-of-distribution dataset**."
      ],
      "metadata": {
        "id": "qu6Z4vj6RJJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M4dZ_8Es3cFw"
      },
      "outputs": [],
      "source": [
        "# Load ResNet model\n",
        "\n",
        "net = WideResNet(depth=40, num_classes=10, widen_factor=2, dropRate=0.3)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net.load_state_dict(torch.load('cifar10_wrn_baseline_epoch_99.pt'))\n",
        "    net.eval()\n",
        "    net.cuda()\n",
        "else:\n",
        "    net.load_state_dict(\n",
        "        torch.load('cifar10_wrn_baseline_epoch_99.pt', map_location=torch.device('cpu'))\n",
        "    )\n",
        "    net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6n7lrVCvCDN3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "8b5f2ab874a44656a6f9b0df3354891a",
            "a68f384f01ae4767b48ae7f05010c6a8",
            "d0f8223a4c764a1395d1c59574b379cb",
            "f69e528870d24614b0a30775f9390e84",
            "5964d448fe98499599a46688ef4ca0a8",
            "e6944d51e24546f1929bf7d158138bf4",
            "624258e0e7bb4602a1e18c6dcc1dad1a",
            "ce6b34fd3e694d01993cedbab8a045d2",
            "5cda9917026e46af9d543ed20839a81a",
            "017ddef3992541d68987f83d705e43d2",
            "98af0cc828194a47b61e5797883520e0",
            "08d9df6c17a949328fa3be254c6a99b4",
            "04aaa489db934f94868fd8b9fc8e1001",
            "99ebdf5121a240cb831ffbc74f2e64ac",
            "a8a1e9d8530942c88b5f0ec773d0a59f",
            "24f23c0170db43fe85c1bd2f72611150",
            "966d707bc1644f82ba1f0a3a98d15d59",
            "69aa5b93132a4b6ab3c7b8c6adfbfeb3",
            "5820871b7f8b4f85b2fd79fff9eeabdd",
            "7f2ab9d29e9c41e593024309cb00d931",
            "12c32c75e8474b798e65723722207575",
            "519e422ce6d3471187889a98a045958f",
            "e44a174327b245838d2c7647680af631",
            "c633a7943a3b426f95cc923d081dae8a",
            "98a9983032e1446591c5da1f529b1c15",
            "8ecb68300ea24a4ebdfed3a9360184fc",
            "e44393f74f8d44d99cb0f0148ff845f2",
            "a496349c56074430aaa9c98825972db3",
            "bce34ffebfd9451c97f124e0a128115b",
            "77e7627c7a6d48b2b56e893b8f49b4c9",
            "b0aef569aca2414bb231a3c2f650e401",
            "08a0cdc475ff4fda804af015712d484f",
            "e90e70d5995e4afd8568b7779746a80a"
          ]
        },
        "outputId": "f0ac21f9-128e-41a5-eba6-a66cb8c116d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b5f2ab874a44656a6f9b0df3354891a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08d9df6c17a949328fa3be254c6a99b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64275384 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e44a174327b245838d2c7647680af631"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ================================\n",
        "# ====== Loading Datasets ========\n",
        "# ================================\n",
        "\n",
        "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
        "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
        "\n",
        "\n",
        "\n",
        "# CIFAR-10\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "cifar_10_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "cifar10_data = cifar_10_data\n",
        "cifar10_loader = torch.utils.data.DataLoader(\n",
        "    cifar10_data,\n",
        "    batch_size=200,\n",
        "    shuffle=False,\n",
        "    num_workers=prefetch,\n",
        "    pin_memory=True                           # https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723\n",
        ")\n",
        "\n",
        "ood_num_examples = len(cifar10_data) // 5\n",
        "\n",
        "\n",
        "\n",
        "# CIFAR-100\n",
        "cifar100_ood_data = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "cifar100_ood_loader = torch.utils.data.DataLoader(\n",
        "    cifar100_ood_data,\n",
        "    batch_size=200,\n",
        "    shuffle=True,\n",
        "    num_workers=prefetch,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Rademacher Noise\n",
        "dummy_targets = torch.ones(ood_num_examples)\n",
        "image_size = (ood_num_examples, 3, 32, 32)\n",
        "\n",
        "ood_data = torch.from_numpy(\n",
        "    np.random.binomial(n=1, p=0.5, size=image_size).astype(np.float32)\n",
        ")\n",
        "ood_data = ood_data * 2 - 1\n",
        "\n",
        "rademacher_ood_data = torch.utils.data.TensorDataset(ood_data, dummy_targets)\n",
        "rademacher_ood_loader = torch.utils.data.DataLoader(\n",
        "    rademacher_ood_data,\n",
        "    batch_size=200,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Street View House Numbers\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "svhn_ood_data = torchvision.datasets.SVHN(\n",
        "    root = \"data\",\n",
        "    split=\"test\",\n",
        "    transform = data_transform,\n",
        "    download = True\n",
        ")\n",
        "\n",
        "svhn_ood_loader = torch.utils.data.DataLoader(\n",
        "    svhn_ood_data,\n",
        "    batch_size=200,\n",
        "    shuffle=True,\n",
        "    num_workers=prefetch,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Predefined Functions\n",
        "\n",
        "These functions will test your implementations of anomaly score calculators. You don't need to do anything here."
      ],
      "metadata": {
        "id": "OmMQ8yfaSLWm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bIeyVeYM6yVL"
      },
      "outputs": [],
      "source": [
        "concat = lambda x: np.concatenate(x, axis=0)\n",
        "to_np = lambda x: x.data.cpu().numpy()\n",
        "\n",
        "def get_ood_scores(\n",
        "    loader : torch.utils.data.DataLoader,\n",
        "    anomaly_score_calculator,\n",
        "    model_net : torch.nn.Module,\n",
        "    use_penultimate : bool=False) -> np.ndarray:\n",
        "\n",
        "    '''\n",
        "    Calculates the anomaly scores for a portion of the given dataset.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "    loader (type: torch.utils.data.DataLoader)\n",
        "    - Contains the batched data of a dataset.\n",
        "    anomaly_score_calculator (type: function)\n",
        "    - Finds anomaly score using last / 2nd last layer.\n",
        "    model_net (type: torch.nn.Module)\n",
        "    - The image classifier.\n",
        "    use_penultimate (type: bool)\n",
        "    - Indicates whether to use penultimate (2nd last) output layer.\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    scores (type: numpy.ndarray, dim: (num_scores,), dtype: float)\n",
        "    - Array of anomaly scores per batch of input.\n",
        "    '''\n",
        "\n",
        "    _score = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # If no GPU, runs on smaller fraction of data\n",
        "        if torch.cuda.is_available():\n",
        "            fraction = 200\n",
        "        else:\n",
        "            fraction = 1000\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            if batch_idx >= (ood_num_examples // fraction):\n",
        "                break\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "\n",
        "            # returns tuple (last layer activations, 2nd last layer activations)\n",
        "            output = model_net(data)\n",
        "\n",
        "            if use_penultimate:\n",
        "                score = anomaly_score_calculator(output[0], output[1])\n",
        "            else:\n",
        "                score = anomaly_score_calculator(output[0])\n",
        "            _score.append(score)\n",
        "\n",
        "    return concat(_score).copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# =================== Printing Utils ===================\n",
        "# ======================================================\n",
        "\n",
        "\n",
        "def get_and_print_results(\n",
        "    ood_loader : torch.utils.data.DataLoader,\n",
        "    anomaly_score_calculator,\n",
        "    model_net : torch.nn.Module,\n",
        "    use_penultimate : bool) -> float:\n",
        "\n",
        "    '''\n",
        "    Returns and prints out the AUROC score of a dataset.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "    ood_loader (type: torch.utils.data.DataLoader)\n",
        "    - Contains the batched data of a dataset.\n",
        "    anomaly_score_calculator (type: function)\n",
        "    - Finds anomaly score given last / 2nd last layer's activations.\n",
        "    model_net (type: torch.nn.Module)\n",
        "    - The image classifier.\n",
        "    use_penultimate (type: bool)\n",
        "    - Whether to use the penultimate (2nd last layer).\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    auroc (type: float)\n",
        "    - The auroc score calculated by the functions you implement.\n",
        "    '''\n",
        "\n",
        "    out_score = get_ood_scores(ood_loader, anomaly_score_calculator, model_net,\n",
        "                               use_penultimate = use_penultimate)\n",
        "    auroc = get_auroc(out_score, in_score) # in_score is global variable\n",
        "    print('AUROC: \\t\\t\\t{:.2f}'.format(100 * auroc) + \"%\")\n",
        "    return auroc\n",
        "\n",
        "\n",
        "\n",
        "all_anomaly_results = {}\n",
        "\n",
        "\n",
        "def print_all_results(\n",
        "    anomaly_score_calculator,\n",
        "    anomaly_score_name : str,\n",
        "    model_net : torch.nn.Module,\n",
        "    model_name : str = \"default_model\",\n",
        "    use_penultimate : bool = False) -> None:\n",
        "\n",
        "    '''\n",
        "    Prints out the AUROC score of all the OOD datasets.\n",
        "\n",
        "    Warning: results added to global dict all_anomaly_results to display later.\n",
        "\n",
        "    Parameters\n",
        "    ---------------------\n",
        "    anomaly_score_calculator (type: function)\n",
        "    - Finds anomaly score given last / 2nd last layer's activations.\n",
        "    anomaly_score_name (type: str)\n",
        "    - The name of the anomaly score method. (To record results)\n",
        "    model_net (type: torch.nn.Module)\n",
        "    - The image classifier.\n",
        "    model_name (type: str)\n",
        "    - The name of the classifier model. (To record results)\n",
        "    use_penultimate (type: bool)\n",
        "    - Whether to use the penultimate (2nd last layer).\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    None\n",
        "    '''\n",
        "\n",
        "    # Prep variables\n",
        "    global in_score, all_anomaly_results # access/modify global var instances\n",
        "    in_score = get_ood_scores(cifar10_loader, anomaly_score_calculator,\n",
        "                              model_net, use_penultimate)\n",
        "    results = []\n",
        "\n",
        "    # Evaluate results\n",
        "    labels = ['Rademacher Noise Detection', '\\nSVHN Detection', '\\nCIFAR-100 Detection']\n",
        "    loaders = [rademacher_ood_loader, svhn_ood_loader, cifar100_ood_loader]\n",
        "\n",
        "    for label, loader in zip(labels, loaders):\n",
        "      print(label)\n",
        "      auroc = get_and_print_results(loader, anomaly_score_calculator, model_net, use_penultimate)\n",
        "      results.append(auroc)\n",
        "\n",
        "    average = sum(results) / len(results)\n",
        "    results.append(average)\n",
        "\n",
        "    # Save results\n",
        "    if not model_name in all_anomaly_results:\n",
        "        all_anomaly_results[model_name] = {}\n",
        "    all_anomaly_results[model_name][anomaly_score_name] = results"
      ],
      "metadata": {
        "id": "uPaE51LaTJ88"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement AUROC Score\n",
        "Fill in the `get_auroc` function. This function will calculate the AUROC score of an out-of-distribution dataset.\n",
        "\n",
        "Hint: you may find the [`sklearn.metrics.roc_auc_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) function helpful. Both `_ood` and `_norm` should be used."
      ],
      "metadata": {
        "id": "epCT4PxHGJ3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def get_auroc(_ood, _norm):\n",
        "    '''\n",
        "    Calculates the AUROC score of a OOD dataset.\n",
        "\n",
        "    Parameters\n",
        "    -------------------\n",
        "    _ood (type: numpy.ndarray, dim: (num_scores,), dtype: float):\n",
        "    - Anomaly scores of images in the out-of-distribution dataset\n",
        "    _norm (type: numpy.ndarray, dim: (num_scores,), dtype: float)\n",
        "    - Anomaly scores of images in the normal (CIFAR-10) dataset\n",
        "\n",
        "    Returns\n",
        "    -------------------\n",
        "    float\n",
        "    - The AUROC score the data in decimal form\n",
        "    '''\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the AUROC score.                                        #\n",
        "    ############################################################################\n",
        "    auroc_score = 0.0\n",
        "    num_scores = len(_ood)\n",
        "    y_true = np.concatenate([np.ones(shape = (num_scores,)), np.zeros(shape = (num_scores,))])\n",
        "    y_score = np.concatenate([_ood, _norm])\n",
        "    auroc_score = roc_auc_score(y_true, y_score)\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "    return auroc_score"
      ],
      "metadata": {
        "id": "FFLwtHgRFWK5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Anomaly Score Calculators\n",
        "Fill in the folllowing functions which calculate the anomaly score given the model's output for a batch of data (the **model's output will contain one [logit](https://stackoverflow.com/questions/34240703/) per image in the batch**).\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "The following equations show how the logits can be used to compute the anomaly score.\n",
        "\n",
        "Max Logit Equation:\n",
        "\n",
        "$ \\LARGE \\text{Score}=-\\text{max}\\ l_k$\n",
        "- Where $k=1,2,...,\\text{num_classes}$ and $l_k$ represents the logits for all $k$ classes.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Max Softmax Equation:\n",
        "\n",
        "$ \\LARGE \\text{Score}=-\\text{max}\\ p(y=k|x)$\n",
        "- Where $p(y=k|x)$ represents the model's predicted probability that input $x$ has its training label $y$ equal to the $kth$ class (for all $k$ classes)\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Cross Entropy Anomaly Equation:\n",
        "\n",
        "$ \\LARGE \\text{Score} = \\bar{l}-\\text{log}∑_{k=1}^{\\text{num_classes}}e^{l_k}$\n",
        "- Where $\\bar{l}$ represents the mean logit value and $k$ and $l_k$ are defined like above."
      ],
      "metadata": {
        "id": "Ot-KkzW1K55s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Lajsgp2BXnc2"
      },
      "outputs": [],
      "source": [
        "# ======================================================\n",
        "# =================== Anomaly Scores ===================\n",
        "# ======================================================\n",
        "\n",
        "\n",
        "\n",
        "def max_logit_anomaly_score(output):\n",
        "    '''\n",
        "    Calculates the max logit anomaly score of a batch of outputs.\n",
        "\n",
        "    Parameters\n",
        "    ---------------------\n",
        "    output (type: torch.Tensor, dim: (num_examples, num_classes), dtype: float)\n",
        "    - The model's output logits for a batch of data.\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    anomaly_score\n",
        "    '''\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the max logit anomaly score.                            #\n",
        "    ############################################################################\n",
        "    score = None\n",
        "    score = -torch.max(output, dim = 1).values\n",
        "\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "    return score.cpu()\n",
        "\n",
        "\n",
        "\n",
        "def max_softmax_anomaly_score(output):\n",
        "    '''\n",
        "    Calculates the max softmax anomaly score of a batch of outputs.\n",
        "\n",
        "    Parameters\n",
        "    ---------------------\n",
        "    output (type: torch.Tensor, dim: (num_examples, num_classes), dtype: float)\n",
        "    - The model's output logits for a batch of data.\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    anomaly_score\n",
        "    '''\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the max softmax anomaly score.                          #\n",
        "    ############################################################################\n",
        "    score = None\n",
        "    score = -torch.softmax(output, dim = 1).max(dim=1).values\n",
        "\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "    return score.cpu()\n",
        "\n",
        "\n",
        "\n",
        "def cross_entropy_anomaly_score(output):\n",
        "    '''\n",
        "    Calculates the cross entropy anomaly score of a batch of outputs.\n",
        "\n",
        "    Parameters\n",
        "    ---------------------\n",
        "    output (type: torch.Tensor, dim: (num_examples, num_classes), dtype: float)\n",
        "    - The model's output logits for a batch of data.\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    anomaly_score\n",
        "    '''\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the cross entropy anomaly score.                        #\n",
        "    ############################################################################\n",
        "    score = None\n",
        "    my_exponentas = torch.exp(output)\n",
        "    my_sum = torch.sum(my_exponentas, dim=1)\n",
        "    my_log = torch.log(my_sum)\n",
        "    score = torch.mean(output, dim=1) - my_log\n",
        "\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "    return score.cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print AUROC Results\n",
        "\n",
        "Run the following cells in order to see how well each of the anomaly score calculators do on the OOD datasets."
      ],
      "metadata": {
        "id": "tmqvyCn-X3RE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Wz78Dx8PM05O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3b8c19-258c-4601-aa57-20a3bea350ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Max Logit AUROC Scores =======\n",
            "Rademacher Noise Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[-10.512507 -10.648192 -10.426215 ... -14.074633  -4.703778 -11.438648]\n",
            "AUROC: \t\t\t70.66%\n",
            "\n",
            "SVHN Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[ -5.2972665  -5.9091806 -10.434359  ... -14.074633   -4.703778\n",
            " -11.438648 ]\n",
            "AUROC: \t\t\t90.88%\n",
            "\n",
            "CIFAR-100 Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[ -7.855615  -10.230577   -3.2131584 ... -14.074633   -4.703778\n",
            " -11.438648 ]\n",
            "AUROC: \t\t\t87.31%\n"
          ]
        }
      ],
      "source": [
        "print(\"======= Max Logit AUROC Scores =======\")\n",
        "print_all_results(max_logit_anomaly_score, \"Max Logit\", net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "jKL87S6dMyFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d60fa7-c90a-42b4-d90a-2f2ea0e7be3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Max Softmax AUROC Scores =======\n",
            "Rademacher Noise Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[-0.9682575  -0.50086933 -0.99474746 ... -0.9999912  -0.680868\n",
            " -0.999962  ]\n",
            "AUROC: \t\t\t80.65%\n",
            "\n",
            "SVHN Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[-0.74307483 -0.69456863 -0.78610444 ... -0.9999912  -0.680868\n",
            " -0.999962  ]\n",
            "AUROC: \t\t\t92.15%\n",
            "\n",
            "CIFAR-100 Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[-0.8030372 -0.9277797 -0.9381026 ... -0.9999912 -0.680868  -0.999962 ]\n",
            "AUROC: \t\t\t88.19%\n"
          ]
        }
      ],
      "source": [
        "print(\"======= Max Softmax AUROC Scores =======\")\n",
        "print_all_results(max_softmax_anomaly_score, \"Max Softmax\", net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Yosj6ofYV9bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c238e2-ec79-41c8-9a60-f1d544e0a8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Cross Entropy AUROC Scores =======\n",
            "Rademacher Noise Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[-10.97749  -11.16936   -9.182621 ... -14.074655  -5.088176 -11.438692]\n",
            "AUROC: \t\t\t70.70%\n",
            "\n",
            "SVHN Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[ -9.111313   -7.6525855 -14.443749  ... -14.074655   -5.088176\n",
            " -11.438692 ]\n",
            "AUROC: \t\t\t90.43%\n",
            "\n",
            "CIFAR-100 Detection\n",
            "(2000,)\n",
            "(2000,)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[ -5.993517  -7.873546 -14.066553 ... -14.074655  -5.088176 -11.438692]\n",
            "AUROC: \t\t\t86.59%\n"
          ]
        }
      ],
      "source": [
        "print(\"======= Cross Entropy AUROC Scores =======\")\n",
        "print_all_results(cross_entropy_anomaly_score, \"Cross Entropy\", net)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement ViM\n",
        "\n",
        "You will now implement [virtual-logit matching (ViM)](https://arxiv.org/abs/2203.10807). It would be helpful to reread Section 4 of the paper, which describes the process of computing the principal space and alpha. This is a rough summary.\n",
        "\n",
        "ViM calculates the **principal space** ($P^\\perp$) using the model's penultimate (second last) layer activations on CIFAR-10 data. Technical notes:\n",
        "- Use the 12 most significant principal components for your principal space.\n",
        "- HINT: You may find it helpful to use [`np.linalg.svd`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html) and then principal component analysis. It is also possible to use covarience to find the principal space.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Then, ViM calculates **alpha** ($\\alpha$) by projecting the training data's features onto the principal space calculated before. This is known as the **residual** ($x^{P^\\perp}$). Alpha is then calculated by the following equation:\n",
        "> $ \\LARGE \\alpha := \\frac{∑^k_{i=1}\\text{max}_{j=1,...,C}\\{l^i_j\\}}{∑^K_{i=1}\\| x_i^{P\\perp} \\|}$\n",
        "\n",
        "In other words, alpha is the sum of each logit's maximum value, divided by the sum of the norms of each feature's residuals.\n",
        "\n",
        "Your calculated alpha should be in the range of 1.5 to 1.9.\n"
      ],
      "metadata": {
        "id": "nq3lnDCbZ6qK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "erJ538Vl1qYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b3e4b5-f1a5-4857-87d2-1d3ee9724178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing principal space...\n",
            "Computing alpha...\n",
            "Your calculated alpha should be in the range of 1.5 to 1.9\n",
            "alpha = 2.2581145763397217\n"
          ]
        }
      ],
      "source": [
        "# You may find the following functions useful\n",
        "from numpy.linalg import pinv, norm, eig              # https://numpy.org/doc/stable/reference/routines.linalg.html\n",
        "from sklearn.covariance import EmpiricalCovariance    # https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "_score = []\n",
        "\n",
        "# Extract fully connected layer's weights and biases\n",
        "w = net.fc.weight.cpu().detach().numpy()\n",
        "b = net.fc.bias.cpu().detach().numpy()\n",
        "\n",
        "# Origin of a new coordinate system of feature space to remove bias\n",
        "u = -np.matmul(pinv(w), b)\n",
        "\n",
        "\n",
        "def compute_ViM_principal_space_and_alpha(\n",
        "    training_data_loader : torch.utils.data.DataLoader,\n",
        "    model_net : torch.nn.Module,\n",
        "    verbose : bool=False) -> list:\n",
        "    '''\n",
        "    Calculates and returns the principal space and alpha values given\n",
        "    the training data the model used.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "    training_data_loader (type: torch.utils.data.DataLoader)\n",
        "    - Contains the training dataset.\n",
        "    model_net (type: torch.nn.Module)\n",
        "    - The classifier model.\n",
        "    verbose (type: bool)\n",
        "    - If true, will print out the alpha value.\n",
        "\n",
        "    Returns\n",
        "    ---------------------\n",
        "    principal_space (type: numpy.ndarray, dim: 128 x 128)\n",
        "    - See equation above.\n",
        "    alpha (type: float)\n",
        "    - See equation above.\n",
        "    '''\n",
        "\n",
        "    # Get the first batch of training data to calculate principal space and alpha\n",
        "    training_data, target = next(iter(training_data_loader))\n",
        "    if torch.cuda.is_available():\n",
        "        training_data = training_data.cuda()\n",
        "\n",
        "    result = model_net(training_data)\n",
        "    logit = result[0]                   # Logits (values before softmax)\n",
        "    penultimate = result[1]             # Penultimate (values before fully connected layer)\n",
        "\n",
        "    logit_id_train = logit.cpu().detach().numpy().squeeze()           # dim: 200 x 10\n",
        "    feature_id_train = penultimate.cpu().detach().numpy().squeeze()   # dim: 200 x 128\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the pricipal space and then comput alpha.               #\n",
        "    ############################################################################\n",
        "    alpha = 0.0\n",
        "    principal_space = None\n",
        "\n",
        "    if verbose:\n",
        "        print('Computing principal space...')\n",
        "\n",
        "    #inner_principal_space, s, Vh = np.linalg.svd(penultimate)\n",
        "    pca = PCA(12)\n",
        "    residual = pca.fit_transform(feature_id_train)\n",
        "\n",
        "    if verbose:\n",
        "        print('Computing alpha...')\n",
        "\n",
        "    # alpha is the sum of each logit's maximum value, divided by the sum of the norms of each feature's residuals.\n",
        "    print('Your calculated alpha should be in the range of 1.5 to 1.9')\n",
        "    residuals = pca.fit_transform(feature_id_train)\n",
        "    sum_of_my_maximums = torch.max(result[0], dim=1).values.sum()\n",
        "    sum_of_my_residual_norms = norm(residuals, axis=1).sum()\n",
        "    alpha = sum_of_my_maximums/sum_of_my_residual_norms\n",
        "    principal_space = residuals\n",
        "\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(f'alpha = {alpha}')\n",
        "\n",
        "    return principal_space.T, alpha\n",
        "\n",
        "principal_space, alpha = compute_ViM_principal_space_and_alpha(cifar10_loader, net, verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement ViM Anomaly Score Calculator\n",
        "\n",
        "Now, implement the ViM anomaly score calculator.\n",
        "\n",
        "First, project the penultimate values onto the principal space from above, which is called the residual. Then, multiply the norm of this residual by alpha to get the **virtual logit score** ($\\text{vlogit}$).\n",
        "\n",
        "Next, compute the **energy score** ($\\text{energy}$) by taking [LogSumExp](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.logsumexp.html) of the logits.\n",
        "\n",
        "Finally, the outputted **anomaly score** is calculated by subtracting the virtual logit by the energy score.\n",
        "\n",
        "$ \\LARGE \\text{vlogit}= \\alpha \\| {x^{P^\\perp}} \\|$\\\n",
        "$ \\LARGE \\text{energy} = \\text{ln}\\sum_{i=1}^C e^{l_i}$\\\n",
        "$ \\LARGE \\text{anomaly_score} = \\text{vlogit} - \\text{energy}$"
      ],
      "metadata": {
        "id": "rmP5powXLnM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzikAO1QYRSh"
      },
      "outputs": [],
      "source": [
        "from scipy.special import logsumexp\n",
        "\n",
        "\n",
        "def ViM_anomaly_score_calculator(output, penultimate):\n",
        "    '''\n",
        "    Calculates the ViM anomaly score of a batch of outputs.\n",
        "\n",
        "    Parameters\n",
        "    ----------------------\n",
        "    output (type: torch.Tensor, dim: 200 x 10)\n",
        "    - The model's output for a batch of data.\n",
        "    penultimate (type: torch.Tensor, dim : 200 x 128)\n",
        "    - The model's penultimate (second-last) layer values for a batch of data.\n",
        "\n",
        "    Returns\n",
        "    -----------------------\n",
        "    score_id (type: numpy.ndarray: dim: 200)\n",
        "    - The anomaly scores for a batch of data.\n",
        "    '''\n",
        "\n",
        "    logit_id_val = output.cpu().detach().numpy().squeeze()          # dim: 200 x 10\n",
        "    feature_id_val = penultimate.cpu().detach().numpy().squeeze()   # dim: 200 x 128\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO:  Calculate the anomaly score.                                      #\n",
        "    ############################################################################\n",
        "    score_id = None\n",
        "\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "\n",
        "    return score_id\n",
        "\n",
        "print(\"======= ViM_anomaly_score_calculator =======\")\n",
        "\n",
        "# Make sure you have the correct ViM values before calculating the score\n",
        "w, b = net.fc.weight.cpu().detach().numpy(), net.fc.bias.cpu().detach().numpy()\n",
        "u = -np.matmul(pinv(w), b)\n",
        "principal_space, alpha = compute_ViM_principal_space_and_alpha(cifar10_loader, net)\n",
        "\n",
        "print_all_results(ViM_anomaly_score_calculator, \"ViM\", net, use_penultimate = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Anomaly Score Results\n",
        "Run the following cell to see how the different anomaly score calculators compare to each other for the OOD datasets. You should see that ViM is superior to other anomaly scores in all of the datasets."
      ],
      "metadata": {
        "id": "jeNAD556O5gN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIJ-zCyvJYp9"
      },
      "outputs": [],
      "source": [
        "# ======================================================\n",
        "# ================== Compare Results ===================\n",
        "# ======================================================\n",
        "\n",
        "def get_results_max(model_name = \"normal\"):\n",
        "    '''\n",
        "    Computes the maximum anomaly score across a range of models and techniques\n",
        "    '''\n",
        "\n",
        "    all_anomaly_results[model_name][\"max\"] = [0,0,0,0,0]\n",
        "\n",
        "    for key in all_anomaly_results[model_name].keys():\n",
        "        if (key != \"max\"):\n",
        "            index = 0\n",
        "\n",
        "            for score in all_anomaly_results[model_name][key]:\n",
        "                all_anomaly_results[model_name][\"max\"][index] = \\\n",
        "                    max(score, all_anomaly_results[model_name][\"max\"][index])\n",
        "                index += 1\n",
        "\n",
        "\n",
        "def compare_all_results():\n",
        "    '''\n",
        "    Creates a nice table to show anomaly scores for many datasets/techniques\n",
        "    '''\n",
        "\n",
        "    for model_name in all_anomaly_results:\n",
        "        to_be_printed = \" \" * (25 - len(model_name)) + model_name\n",
        "        dataset_names = [\"Rademacher\", \"SVHN\", \"CIFAR-100\", \"Average\"]\n",
        "        for name in dataset_names:\n",
        "            to_be_printed += \" | \" + \" \"*(6-math.ceil(len(name)/2)) + \\\n",
        "                                name + \" \"*(6-math.floor(len(name)/2))\n",
        "\n",
        "        print(to_be_printed)\n",
        "        print(\"=\" * (25 + len(dataset_names) * 15))\n",
        "\n",
        "        get_results_max(model_name = model_name)\n",
        "        for key in all_anomaly_results[model_name].keys():\n",
        "            if (key != \"max\"):\n",
        "                to_be_printed = \" \"*(25-len(key)) + key\n",
        "                index = 0\n",
        "\n",
        "                for result in all_anomaly_results[model_name][key]:\n",
        "                    if (all_anomaly_results[model_name][\"max\"][index] == result):\n",
        "                        result = \"*\" + '{:.2f}'.format(round(result * 100, 2)) + \"%\"\n",
        "                    else:\n",
        "                        result = '{:.2f}'.format(round(result * 100, 2)) + \"%\"\n",
        "                    to_be_printed += \" | \" + \" \"*(6-math.ceil(len(result)/2)) + \\\n",
        "                                        result + \" \"*(6-math.floor(len(result)/2))\n",
        "                    index += 1\n",
        "\n",
        "                print(to_be_printed)\n",
        "        print()\n",
        "\n",
        "    print(\"\\n* highlights the maximum AUROC Score for an OOD Dataset\")\n",
        "\n",
        "compare_all_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Now, check if models trained using data augmentation methods for robustness help in out-of-distribution detection.\n",
        "\n",
        "Load a CIFAR-10 model that used PixMix data augmentation during training, and see how it fares compared to the default model that did not use data augmentation."
      ],
      "metadata": {
        "id": "lOftK8KC8fSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1mjIfbb3mfXXvAZ1sBnjotFr5yYFmLi68 # Downloading PixMix model\n",
        "!gdown 1skZT6yplO-Sv4M8Ksgzx14cTY3H-HgOa # Downlaoding wideresnet class"
      ],
      "metadata": {
        "id": "ANy7vzim9PbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wideresnet_with_pen import WideResNet as WideResNet2"
      ],
      "metadata": {
        "id": "wx8QTsLj9QAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the PixMix model\n",
        "\n",
        "pixmix_net = WideResNet2(depth=40, num_classes=10, widen_factor=4, drop_rate=0.3)\n",
        "pixmix_net = torch.nn.DataParallel(pixmix_net)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    checkpoint = torch.load('checkpoint.pth.tar')\n",
        "    pixmix_net.load_state_dict(checkpoint['state_dict'])\n",
        "    net.eval()\n",
        "    net.cuda()\n",
        "else:\n",
        "    checkpoint = torch.load('checkpoint.pth.tar', map_location=torch.device('cpu'))\n",
        "    pixmix_net.load_state_dict(checkpoint['state_dict'])\n",
        "    net.eval()"
      ],
      "metadata": {
        "id": "TQiyBmip9eYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PixMix Model Testing\n",
        "\n",
        "Now, test the PixMix model with the same anomaly score calculators you coded before."
      ],
      "metadata": {
        "id": "XRje54Ip-w3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======= Max Logit AUROC Scores =======\")\n",
        "print_all_results(max_logit_anomaly_score, \"Max Logit\", pixmix_net, model_name = \"pixmix_trained_model\")"
      ],
      "metadata": {
        "id": "W_MVibEl9mgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======= Max Softmax Probability AUROC Scores =======\")\n",
        "print_all_results(max_softmax_anomaly_score, \"Max Softmax Probability\", pixmix_net, model_name = \"pixmix_trained_model\")"
      ],
      "metadata": {
        "id": "q3Nx8ieU9npx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======= Cross Entropy AUROC Scores =======\")\n",
        "print_all_results(cross_entropy_anomaly_score, \"Cross Entropy\", pixmix_net, model_name = \"pixmix_trained_model\")"
      ],
      "metadata": {
        "id": "umUyonHj9oGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======= ViM_anomaly_score_calculator =======\")\n",
        "w, b = pixmix_net.module.fc.weight.cpu().detach().numpy(), pixmix_net.module.fc.bias.cpu().detach().numpy()\n",
        "u = -np.matmul(pinv(w), b)\n",
        "principal_space, alpha = compute_ViM_principal_space_and_alpha(cifar10_loader, pixmix_net)\n",
        "print_all_results(ViM_anomaly_score_calculator, \"ViM\", pixmix_net, model_name = \"pixmix_trained_model\", use_penultimate = True)"
      ],
      "metadata": {
        "id": "mPyLCKXK9rtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare No-data-augmentation Model vs PixMix Model\n",
        "\n",
        "Let us now compare how the default model compared to the PixMix model by running the following cell.\n",
        "\n",
        "You should see that the PixMix model successfully helps us in OOD detection, and has a higher AUROC score."
      ],
      "metadata": {
        "id": "jt-XKgcq-8G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_all_results()"
      ],
      "metadata": {
        "id": "xBa5Gz0K9sTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b5f2ab874a44656a6f9b0df3354891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a68f384f01ae4767b48ae7f05010c6a8",
              "IPY_MODEL_d0f8223a4c764a1395d1c59574b379cb",
              "IPY_MODEL_f69e528870d24614b0a30775f9390e84"
            ],
            "layout": "IPY_MODEL_5964d448fe98499599a46688ef4ca0a8"
          }
        },
        "a68f384f01ae4767b48ae7f05010c6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6944d51e24546f1929bf7d158138bf4",
            "placeholder": "​",
            "style": "IPY_MODEL_624258e0e7bb4602a1e18c6dcc1dad1a",
            "value": ""
          }
        },
        "d0f8223a4c764a1395d1c59574b379cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6b34fd3e694d01993cedbab8a045d2",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cda9917026e46af9d543ed20839a81a",
            "value": 170498071
          }
        },
        "f69e528870d24614b0a30775f9390e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_017ddef3992541d68987f83d705e43d2",
            "placeholder": "​",
            "style": "IPY_MODEL_98af0cc828194a47b61e5797883520e0",
            "value": " 170499072/? [00:02&lt;00:00, 76122885.74it/s]"
          }
        },
        "5964d448fe98499599a46688ef4ca0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6944d51e24546f1929bf7d158138bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624258e0e7bb4602a1e18c6dcc1dad1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6b34fd3e694d01993cedbab8a045d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cda9917026e46af9d543ed20839a81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "017ddef3992541d68987f83d705e43d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98af0cc828194a47b61e5797883520e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08d9df6c17a949328fa3be254c6a99b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04aaa489db934f94868fd8b9fc8e1001",
              "IPY_MODEL_99ebdf5121a240cb831ffbc74f2e64ac",
              "IPY_MODEL_a8a1e9d8530942c88b5f0ec773d0a59f"
            ],
            "layout": "IPY_MODEL_24f23c0170db43fe85c1bd2f72611150"
          }
        },
        "04aaa489db934f94868fd8b9fc8e1001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_966d707bc1644f82ba1f0a3a98d15d59",
            "placeholder": "​",
            "style": "IPY_MODEL_69aa5b93132a4b6ab3c7b8c6adfbfeb3",
            "value": ""
          }
        },
        "99ebdf5121a240cb831ffbc74f2e64ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5820871b7f8b4f85b2fd79fff9eeabdd",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f2ab9d29e9c41e593024309cb00d931",
            "value": 169001437
          }
        },
        "a8a1e9d8530942c88b5f0ec773d0a59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c32c75e8474b798e65723722207575",
            "placeholder": "​",
            "style": "IPY_MODEL_519e422ce6d3471187889a98a045958f",
            "value": " 169001984/? [00:02&lt;00:00, 84121786.65it/s]"
          }
        },
        "24f23c0170db43fe85c1bd2f72611150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966d707bc1644f82ba1f0a3a98d15d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69aa5b93132a4b6ab3c7b8c6adfbfeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5820871b7f8b4f85b2fd79fff9eeabdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2ab9d29e9c41e593024309cb00d931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12c32c75e8474b798e65723722207575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519e422ce6d3471187889a98a045958f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e44a174327b245838d2c7647680af631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c633a7943a3b426f95cc923d081dae8a",
              "IPY_MODEL_98a9983032e1446591c5da1f529b1c15",
              "IPY_MODEL_8ecb68300ea24a4ebdfed3a9360184fc"
            ],
            "layout": "IPY_MODEL_e44393f74f8d44d99cb0f0148ff845f2"
          }
        },
        "c633a7943a3b426f95cc923d081dae8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a496349c56074430aaa9c98825972db3",
            "placeholder": "​",
            "style": "IPY_MODEL_bce34ffebfd9451c97f124e0a128115b",
            "value": ""
          }
        },
        "98a9983032e1446591c5da1f529b1c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e7627c7a6d48b2b56e893b8f49b4c9",
            "max": 64275384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0aef569aca2414bb231a3c2f650e401",
            "value": 64275384
          }
        },
        "8ecb68300ea24a4ebdfed3a9360184fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08a0cdc475ff4fda804af015712d484f",
            "placeholder": "​",
            "style": "IPY_MODEL_e90e70d5995e4afd8568b7779746a80a",
            "value": " 64275456/? [00:03&lt;00:00, 40395467.74it/s]"
          }
        },
        "e44393f74f8d44d99cb0f0148ff845f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a496349c56074430aaa9c98825972db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce34ffebfd9451c97f124e0a128115b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77e7627c7a6d48b2b56e893b8f49b4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0aef569aca2414bb231a3c2f650e401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08a0cdc475ff4fda804af015712d484f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90e70d5995e4afd8568b7779746a80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
